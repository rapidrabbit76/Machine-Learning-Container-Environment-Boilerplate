version: "3.8"
services:
  lab:
    build:
      context: .
      dockerfile: docker/pytorch/Dockerfile
      args:
        TAG: 1.12.0-cuda11.3-cudnn8-runtime
        USERNAME: ${USERNAME}
        USER_UID: ${UID}
        USER_GID: ${GID}
    command: tail -f /dev/null
    volumes:
      - ./:/experiment

    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
